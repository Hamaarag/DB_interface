# Hamaarag Biodiversity Database â€“ Progress Summary (May 2025)

## âœ… Completed Implementation Steps (1â€“12)

### 1â€“9: Schema Design and Local Setup
- âœ… **Database Software**: PostgreSQL
- âœ… **Cloud Provider**: Google Cloud SQL
- âœ… **Design Platform**: dbdiagram.io
- âœ… **Schema Design**: Completed for taxonomy, traits, conservation status
  - Normalized to 3NF with use of UUIDs and ENUM constraints
  - Separate `taxon_entity` and `taxon_version` tables support temporal versioning
- âœ… **Database Management Tools**: pgAdmin for local + cloud management
- âœ… **Local Setup**: Local PostgreSQL testing environment created and loaded
- âœ… **Schema Export**: SQL DDL generated from dbdiagram.io
- âœ… **Local Deployment**: Schema deployed and validated locally
- âœ… **Local Testing**: Trait and taxonomy tables successfully populated

### 10â€“12: Cloud SQL Deployment
- âœ… **Cloud SQL Instance Setup**: PostgreSQL instance created on GCP
- âœ… **Cloud Deployment**: Schema deployed to Google Cloud SQL
- âœ… **Cloud Testing**: All loading scripts tested and validated; view creation successful

---

## ğŸ§¬ Core Achievements

- Full bulk loading for `taxon_entity`, `taxon_version`, `species_traits`, and related trait tables using `dbWriteTable()`
- Logging of skipped records and unmatched ENUM values to CSV
- Creation of `taxon_trait_view`: one row per current `taxon_version`, with key fields and traits
- ENUM validation and PostgreSQL constraints maintained
- Query performance improvements via data.table and view flattening

---

## ğŸ”œ Remaining Implementation Steps (13â€“16)

### 13. Design and Implement Additional Datasets
Planned expansions include:
- ğŸ“ **Species Observations** (event-level)
- ğŸ“ **Abundance and Effort Data**
- ğŸ“ **Monitoring Unit Metadata**
- ğŸ“ **New Traits**:
  - Whether the species breeds in a monitoring unit (taxon Ã— unit)
  - Whether the species interacts with the sampling plot (taxon-specific trait)

### 14. Load Real Data
- âœ… **Completed** for taxonomy and trait tables
- â³ Pending for species observations and new trait structures

### 15. Optimize Performance & Indexing
- Will be revisited once observational data and spatial joins are implemented

### 16. Implement API or Query Interface
- To support interaction from R/Python and dashboards (e.g., Shiny apps)

---

## ğŸŒ‰ Future Strategy â€“ Lakehouse Architecture

In parallel with PostgreSQL development, we plan to implement a **lakehouse-style system** for handling:
- Raw field-collected data (e.g., Fulcrum, Survey123)
- Schema-on-read access to semi-structured observation forms
- Long-term storage of opportunistic and bulk ecological data

The architecture will combine:
- PostgreSQL (curated, validated data)
- Google Cloud Storage or BigQuery (raw event ingestion and archival)
- Automated pipelines for ingestion and transformation

---

